{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwt5Ko25F6UK",
        "outputId": "db7f2201-2155-4cb1-cf87-f109636845e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzUBjACWFjoC"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "1. load csv file (panda, numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W8RwWK39FjoE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "dataset = fetch_ucirepo(id=94)\n",
        "\n",
        "x = dataset.data.features\n",
        "y = dataset.data.targets\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "probSpam = y_train[y_train == 1].shape[0] / len(y_train)\n",
        "probNotSpam = y_train[y_train == 0].shape[0] / len(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SMl7q9sFjoE"
      },
      "source": [
        "# Naive Bayes Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XV4i6dPsFjoF"
      },
      "outputs": [],
      "source": [
        "def naiveBayes(x_train, x_test, y_train, y_test):\n",
        "  for label in x_train.columns:\n",
        "    labelProbSpam, labelProbNotSpam = calculate_likelihood(label, x_train, y_train)\n",
        "    likelihoods[label] = {\"spam\": labelProbSpam, \"notSpam\": labelProbNotSpam}\n",
        "\n",
        "def calculate_likelihood(label, x_train, y_train):\n",
        "    \"\"\"Calculate likelihood probabilities.\"\"\"\n",
        "    smoothing = 1\n",
        "    numLabels = x_train.shape[1]\n",
        "    labelSpamCount = 0\n",
        "    labelSpamNotCount = 0\n",
        "\n",
        "    spamTotal = y_train[y_train == 1].shape[0]\n",
        "    notSpamTotal = y_train[y_train == 0].shape[0]\n",
        "\n",
        "    for item in range(0, len(x_train[label])):\n",
        "        if x_train[label].iloc[item] > 0:\n",
        "          if y_train.iloc[item][0] == 1:\n",
        "            labelSpamCount += 1\n",
        "          else:\n",
        "            labelSpamNotCount += 1\n",
        "\n",
        "    labelSpam = labelSpamCount / spamTotal\n",
        "    labelNotSpam = labelSpamNotCount / notSpamTotal\n",
        "\n",
        "    spamProb = (labelSpam + 1) / (spamTotal + smoothing * numLabels)\n",
        "    notSpamProb = (labelNotSpam + 1) / (spamTotal + smoothing * numLabels)\n",
        "\n",
        "    return spamProb, notSpamProb\n",
        "\n",
        "def naiveBayesClassifier(x_test, likelihoods, spamProb, notSpamProb):\n",
        "  result = []\n",
        "  spamLogProb = np.log(spamProb)\n",
        "  notSpamLogProb = np.log(notSpamProb)\n",
        "\n",
        "  for row in range(0, len(x_test)):\n",
        "    for label in x_test.columns:\n",
        "      if x_test[label].iloc[row] > 0:\n",
        "        spamLogProb += np.log(likelihoods[label][\"spam\"])\n",
        "        notSpamLogProb += np.log(likelihoods[label][\"notSpam\"])\n",
        "\n",
        "    if spamLogProb > notSpamLogProb:\n",
        "      result.append(1)\n",
        "    else:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jRvHTlW0DYA"
      },
      "source": [
        "# K Nearest Neighbors Implementaion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "bb4FHGGXFjoG"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(x_test, x_train):\n",
        "    pointSum = 0\n",
        "    neighbors = []\n",
        "    all_distances = []\n",
        "    for test_row in range(0, len(x_test)):\n",
        "      for email in range(0, len(x_train)):\n",
        "        for label in range(1, len(x_test[:].iloc[test_row]) - 1):\n",
        "          'print(\"test row index: \", test_row, \"email index: \", email, \"label index: \", label)'\n",
        "          pointSum += (x_test.iloc[label][test_row] - x_train.iloc[email][label]) ** 2\n",
        "        neighbors.append(np.sqrt(pointSum))\n",
        "      all_distances.append(neighbors)\n",
        "    return all_distances\n",
        "\n",
        "def knn_predict(x_train, y_train, x_test, k=3):\n",
        "    y_pred = []\n",
        "    distances = euclidean_distance(x_test, x_train)\n",
        "    print(\"Distance Calculated: \", distances)\n",
        "    k_indices = np.argsort(distances)[:k]\n",
        "    k_nearest_labels = [y_train.iloc[0][i] for i in k_indices]\n",
        "    most_common = np.bincount(k_nearest_labels).argmax()\n",
        "    y_pred.append(most_common)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUzUupva0Fxw"
      },
      "source": [
        "# Logistic Regression Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ztTHdD3bFjoH"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"Sigmoid function.\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def cost_function(x, y, theta):\n",
        "    \"\"\"Cost function.\"\"\"\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(x, theta))\n",
        "    return (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "\n",
        "def gradient_descent(x, y, theta, learning_rate, num_iterations):\n",
        "    \"\"\"Gradient descent to optimize parameters.\"\"\"\n",
        "    m = len(y)\n",
        "    costs = []\n",
        "    for _ in range(num_iterations):\n",
        "        h = sigmoid(np.dot(x, theta))\n",
        "        gradient = np.dot(x.T, (h - y)) / m\n",
        "        theta -= learning_rate * gradient\n",
        "        cost = cost_function(x, y, theta)\n",
        "        costs.append(cost)\n",
        "    return theta, costs\n",
        "\n",
        "def logistic_regression_train(x_train, y_train, learning_rate=0.01, num_iterations=1000):\n",
        "    \"\"\"Train Logistic Regression classifier.\"\"\"\n",
        "    intercept = np.ones((x_train.shape[0], 1))\n",
        "    x_train = np.concatenate((intercept, x_train), axis=1)\n",
        "    theta = np.zeros(x_train.shape[1])\n",
        "    theta, _ = gradient_descent(x_train, y_train, theta, learning_rate, num_iterations)\n",
        "    return theta\n",
        "\n",
        "def logistic_regression_predict(x_test, theta):\n",
        "    \"\"\"Predict using Logistic Regression classifier.\"\"\"\n",
        "    intercept = np.ones((x_test.shape[0], 1))\n",
        "    x_test = np.concatenate((intercept, x_test), axis=1)\n",
        "    return sigmoid(np.dot(x_test, theta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAssSW_I0GvA"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0MQ0eo0MnmB"
      },
      "outputs": [],
      "source": [
        "def assessment(results, y_train):\n",
        "  falsePos = 0;\n",
        "  for value in range(0, len(y_train)):\n",
        "    if results[value] == 1 and y_train[\"Class\"].iloc[value] != 1:\n",
        "      falsePos += 1\n",
        "  return falsePos, len(y_train) - falsePos\n",
        "\n",
        "likelihoods = {}\n",
        "naiveBayes(x_train, x_test, y_train, y_test)\n",
        "predictions = naiveBayesClassifier(x_test, likelihoods, probSpam, probNotSpam)\n",
        "falsePos, truePos = assessment(predictions, y_test)\n",
        "accuracy = accuracy_score(predictions, y_test)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy)\n",
        "print(\"Naive Bayes False Positives\", falsePos)\n",
        "print(\"Naive Bayes True Positives\", truePos)\n",
        "\n",
        "k = 5\n",
        "y_pred = knn_predict(x_train, y_train, x_test, k)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "falsePos, truePos = assessment(predictions, y_test)\n",
        "print(\"KNN Accuracy:\", accuracy)\n",
        "print(\"KNN False Positives\", falsePos)\n",
        "print(\"KNN True Positives\", truePos)\n",
        "\n",
        "theta = logistic_regression_train(x_train, y_train)\n",
        "predictions = logistic_regression_predict(x_test, theta)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "falsePos, truePos = assessment(predictions, y_test)\n",
        "print(\"LR Accuracy:\", accuracy)\n",
        "print(\"LR False Positives\", falsePos)\n",
        "print(\"LR True Positives\", truePos)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}