{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install sklearn\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwt5Ko25F6UK",
        "outputId": "3cc08686-c28c-478c-97aa-875d34a91f2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzUBjACWFjoC"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "1. load csv file (panda, numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W8RwWK39FjoE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "dataset = fetch_ucirepo(id=94)\n",
        "\n",
        "x = dataset.data.features\n",
        "y = dataset.data.targets\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "probSpam = y_train[y_train == 1].shape[0] / len(y_train)\n",
        "probNotSpam = y_train[y_train == 0].shape[0] / len(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SMl7q9sFjoE"
      },
      "source": [
        "# Naive Bayes Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XV4i6dPsFjoF"
      },
      "outputs": [],
      "source": [
        "def naiveBayes(x_train, x_test, y_train, y_test):\n",
        "  for label in x_train.columns:\n",
        "    labelProbSpam, labelProbNotSpam = calculate_likelihood(label, x_train, y_train)\n",
        "    likelihoods[label] = {\"spam\": labelProbSpam, \"notSpam\": labelProbNotSpam}\n",
        "\n",
        "def calculate_likelihood(label, x_train, y_train):\n",
        "    \"\"\"Calculate likelihood probabilities.\"\"\"\n",
        "    smoothing = 1\n",
        "    numLabels = x_train.shape[1]\n",
        "    labelSpamCount = 0\n",
        "    labelSpamNotCount = 0\n",
        "\n",
        "    spamTotal = y_train[y_train == 1].shape[0]\n",
        "    notSpamTotal = y_train[y_train == 0].shape[0]\n",
        "\n",
        "    for item in range(0, len(x_train[label])):\n",
        "        if x_train[label].iloc[item] > 0:\n",
        "          if y_train.iloc[item][0] == 1:\n",
        "            labelSpamCount += 1\n",
        "          else:\n",
        "            labelSpamNotCount += 1\n",
        "\n",
        "    labelSpam = labelSpamCount / spamTotal\n",
        "    labelNotSpam = labelSpamNotCount / notSpamTotal\n",
        "\n",
        "    spamProb = (labelSpam + 1) / (spamTotal + smoothing * numLabels)\n",
        "    notSpamProb = (labelNotSpam + 1) / (spamTotal + smoothing * numLabels)\n",
        "\n",
        "    return spamProb, notSpamProb\n",
        "\n",
        "def naiveBayesClassifier(x_test, likelihoods, spamProb, notSpamProb):\n",
        "  result = []\n",
        "  spamLogProb = np.log(spamProb)\n",
        "  notSpamLogProb = np.log(notSpamProb)\n",
        "\n",
        "  for row in range(0, len(x_test)):\n",
        "    for label in x_test.columns:\n",
        "      if x_test[label].iloc[row] > 0:\n",
        "        spamLogProb += np.log(likelihoods[label][\"spam\"])\n",
        "        notSpamLogProb += np.log(likelihoods[label][\"notSpam\"])\n",
        "\n",
        "    if spamLogProb > notSpamLogProb:\n",
        "      result.append(1)\n",
        "    else:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXyRfd35yRPd"
      },
      "source": [
        "#Naive bayes\n",
        "\n",
        "1. model learning:\n",
        "\n",
        "   Note:\n",
        "\n",
        "   features: remove attributes that is not related to word (the last four attributes)\n",
        "\n",
        "   labels: the last column\n",
        "\n",
        "   count P(c) -> how many samples are positive, and how many are negtive\n",
        "\n",
        "   if freq_word>0, then this word exists. You could use this to calculate P(a|c) -> for each class, what is the prob of each word\n",
        "\n",
        "   remember to use laplace smoothing.\n",
        "\n",
        "2. model evaluation (on val dataset -> performance(model, val)):\n",
        "   \n",
        "   for each new sample, $\\prod{P(a|c)}P(c)$; and find the maximum class\n",
        "   \n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jRvHTlW0DYA"
      },
      "source": [
        "# KNN\n",
        "1. model learning: None\n",
        "\n",
        "2. model evaluation(on val dataset): You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "\n",
        "   ```\n",
        "   Note:\n",
        "   parallel programing\n",
        "   numpy.cos() to calcuate the similarity\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "bb4FHGGXFjoG"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(test_row, x_train):\n",
        "    pointSum = 0\n",
        "    neighbors = []\n",
        "    for email in range(0, len(x_train)):\n",
        "      for label in range(0, len(x_train.columns)):\n",
        "        pointSum += (test_row.iloc[label] - x_train.iloc[label][email]) ** 2\n",
        "      neighbors.append(np.sqrt(pointSum))\n",
        "    return neighbors\n",
        "\n",
        "def predict(x_train, y_train, x_test, k=3):\n",
        "    y_pred = []\n",
        "    for test_point in x_test.iterrows():\n",
        "        distances = euclidean_distance(test_point, x_train)\n",
        "        k_indices = np.argsort(distances)[:k]\n",
        "        k_nearest_labels = [y_train.iloc[0][i] for i in k_indices]\n",
        "        most_common = np.bincount(k_nearest_labels).argmax()\n",
        "        y_pred.append(most_common)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUzUupva0Fxw"
      },
      "source": [
        "# LR\n",
        "\n",
        "1. model learning: You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "    \n",
        "    $y = sigmoid(MX)$\n",
        "\n",
        "step 1: add one more column (all value is 1) in X -> X' = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "step 2:vector M = np.random.randn(len(X[0])+1, 1);\n",
        "\n",
        "key formula for step 3 (Note: n is the size of the TRAINING dataset; $cdot$ is dot production ):\n",
        "\n",
        "1. $pred_y = sigmoid(M\\cdot X')$\n",
        "\n",
        "2. $loss = -\\sum(y\\cdot log(pred_y)+(1-y)\\cdot log(1-pred_y))/n$\n",
        "\n",
        "3. $gm=X'\\cdot (pred_y - y)*2/n$\n",
        "\n",
        "Step 3 example code:\n",
        "   ```\n",
        "   #Step 3: performing gradient descent on whole dataset:\n",
        "   best_model = M\n",
        "   best_performace = 0\n",
        "   for i in range(epoch):\n",
        "     pred_y = ...\n",
        "     gm = ...\n",
        "     _p = performace(model, val)\n",
        "     if _p > best_performance:\n",
        "        best_model = M\n",
        "        best_performance = _p\n",
        "     M = M - learning_rate*gm\n",
        "   ```\n",
        "\n",
        "2. model evaluation(on val dataset):\n",
        "  \n",
        "   calculate pred_y, if more than 0.5, then the predicted label is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ztTHdD3bFjoH"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"Sigmoid function.\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def cost_function(x, y, theta):\n",
        "    \"\"\"Cost function.\"\"\"\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(x, theta))\n",
        "    return (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "\n",
        "def gradient_descent(x, y, theta, learning_rate, num_iterations):\n",
        "    \"\"\"Gradient descent to optimize parameters.\"\"\"\n",
        "    m = len(y)\n",
        "    costs = []\n",
        "    for _ in range(num_iterations):\n",
        "        h = sigmoid(np.dot(x, theta))\n",
        "        gradient = np.dot(x.T, (h - y)) / m\n",
        "        theta -= learning_rate * gradient\n",
        "        cost = cost_function(x, y, theta)\n",
        "        costs.append(cost)\n",
        "    return theta, costs\n",
        "\n",
        "def logistic_regression_train(x_train, y_train, learning_rate=0.01, num_iterations=1000):\n",
        "    \"\"\"Train Logistic Regression classifier.\"\"\"\n",
        "    intercept = np.ones((x_train.shape[0], 1))\n",
        "    x_train = np.concatenate((intercept, x_train), axis=1)\n",
        "    theta = np.zeros(x_train.shape[1])\n",
        "    theta, _ = gradient_descent(x_train, y_train, theta, learning_rate, num_iterations)\n",
        "    return theta\n",
        "\n",
        "def logistic_regression_predict(x_test, theta):\n",
        "    \"\"\"Predict using Logistic Regression classifier.\"\"\"\n",
        "    intercept = np.ones((x_test.shape[0], 1))\n",
        "    x_test = np.concatenate((intercept, x_test), axis=1)\n",
        "    return sigmoid(np.dot(x_test, theta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAssSW_I0GvA"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "e0MQ0eo0MnmB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "279e6d7d-9220-4637-d94c-1263208563b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.5841476655808904\n",
            "Naive Bayes False Positives 2\n",
            "Naive Bayes True Positives 919\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unable to coerce to Series, length must be 1: given 3680",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-9f76233c526f>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KNN Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m '''\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-89f6141b6495>\u001b[0m in \u001b[0;36mlogistic_regression_train\u001b[0;34m(x_train, y_train, learning_rate, num_iterations)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-89f6141b6495>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(x, y, theta, learning_rate, num_iterations)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m     ):\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_dispatch_ufunc_to_dunder_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rsub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__mul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7453\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_prepare_scalar_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7457\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    253\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 1: given 3680"
          ]
        }
      ],
      "source": [
        "def assessment(results, y_train):\n",
        "  falsePos = 0;\n",
        "  for value in range(0, len(y_train)):\n",
        "    if results[value] == 1 and y_train[\"Class\"].iloc[value] != 1:\n",
        "      falsePos += 1\n",
        "  return falsePos, len(y_train) - falsePos\n",
        "\n",
        "likelihoods = {}\n",
        "naiveBayes(x_train, x_test, y_train, y_test)\n",
        "predictions = naiveBayesClassifier(x_test, likelihoods, probSpam, probNotSpam)\n",
        "falsePos, truePos = assessment(predictions, y_test)\n",
        "accuracy = accuracy_score(predictions, y_test)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy)\n",
        "print(\"Naive Bayes False Positives\", falsePos)\n",
        "print(\"Naive Bayes True Positives\", truePos)\n",
        "'''\n",
        "k = 5\n",
        "y_pred = knn_predict(x_train, y_train, x_test, k)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"KNN Accuracy:\", accuracy)\n",
        "'''\n",
        "theta = logistic_regression_train(x_train, y_train)\n",
        "predictions = logistic_regression_predict(x_test, theta)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}